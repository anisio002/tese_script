# -*- coding: utf-8 -*-
"""IRECE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14iS8RZMkZPl26OS4UrhWHvvhrv8g07X3
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import csv
import time
from math import sqrt
save_path = "/content/drive/MyDrive/Doutorado/Dados/Models"
path = "/content/drive/MyDrive/Doutorado/Dados/Pareados"
file_path = "/content/drive/MyDrive/Doutorado/Dados/Redes/"

# dadosCampinaVerde = pd.read_csv(path + '/MG-CAMPINA VERDE.csv',sep=',')
# dadosSorriso = pd.read_csv(path + '/MT-SORRISO.csv',sep=',')
# dadosDiamante = pd.read_csv(path + '/PR-DIAMANTE DO NORTE.csv',sep=',')
# dadosCampo = pd.read_csv(path + '/RS-CAMPOBOM.csv',sep=',')

# dadosBarcelos = pd.read_csv(path + '/AM-BARCELOS.csv',sep=',')
# dadosMacapa = pd.read_csv(path + '/AP-MACAPÁ.csv',sep=',')
# dadosPetrolina = pd.read_csv(path + '/PE-PETROLINA.csv',sep=',')
# dadosIrece = pd.read_csv(path + '/BA-IRÊCE.csv',sep=',')

listNames = ["RS-CAMPOBOM","MT-SORRISO","PR-DIAMANTE DO NORTE","MG-CAMPINA VERDE","AM-BARCELOS", "AP-MACAPÁ", "PE-PETROLINA", "BA-IRÊCE"]
fields = ['City', 'Fold','RMSE','Time', 'Epoch']

city = "BA-IRÊCE"
data = pd.read_csv(path + '/BA-IRÊCE.csv',sep=',')

fields = ['City', 'Fold','RMSE','Time', 'Epoch','Training_Loss', 'Training_Accuracy', 'Test_Loss', 'Test_Accuracy']
modelo = 'PINN1_20'
foldMax = 8
foldMin = 0

pos = ['umid_inst', 'pto_orvalho_inst', 'pressao', 'radiacao', 'vento_vel']

test_size= 0.2
num_folds = 10
epochs = 3000
seed = 7
learning_rate = 1e-4
min_delta = 0.0001
patience = 10

y = data['temp_inst'].to_numpy()
X = data.drop(['temp_inst'],axis = 1)

scaler = StandardScaler().fit(X)
X = scaler.transform(X)

with open(file_path + modelo+'_'+city+'.csv', 'a', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(fields)

def plot_training_history(history):
    # Plot da perda (loss) e métrica de validação ao longo das épocas
    plt.figure(figsize=(10, 6))

    # Plot da perda de treinamento
    plt.plot(history.epoch, history.history['loss'], label='Perda (Treinamento)', color='blue')
    # Plot da perda de validação
    plt.plot(history.epoch, history.history['val_loss'], label='Perda (Validação)', color='orange')

    plt.xlabel('Época')
    plt.ylabel('Perda')
    plt.title('Perda de Treinamento e Validação')
    plt.legend()
    plt.grid(True)

    # Adicionar grades mais leves
    plt.minorticks_on()
    plt.grid(which='major', linestyle='-', linewidth='0.5', color='black')
    plt.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')

    # Adicionar estilo de fundo branco
    plt.style.use('seaborn-white')

    # Ajustar fontes
    plt.rc('font', size=12)
    plt.rc('axes', titlesize=16)
    plt.rc('axes', labelsize=14)
    plt.rc('xtick', labelsize=12)
    plt.rc('ytick', labelsize=12)
    plt.rc('legend', fontsize=12)

    plt.tight_layout()
    plt.show()



def plot_training_history_f(history, model, X_train, y_train, X_val, y_val):
    # Fazer previsões usando o modelo
    y_train_pred = model.predict(X_train)
    y_val_pred = model.predict(X_val)

    # Plot da perda (loss) e métrica de validação ao longo das épocas
    plt.figure(figsize=(10, 6))

    # Plot da perda de treinamento
    plt.plot(history.epoch, history.history['loss'], label='Perda (Treinamento)', color='blue')
    # Plot da perda de validação
    plt.plot(history.epoch, history.history['val_loss'], label='Perda (Validação)', color='orange')

    plt.xlabel('Época')
    plt.ylabel('Perda')
    plt.title(f"Função de Perda no Treinamento e Validação ({city})")
    plt.legend()
    plt.grid(True)

    # Plot dos valores estimados de y no treinamento e validação
    plt.figure(figsize=(10, 6))

    plt.plot(y_train, label='Valores Verdadeiros (Treinamento)', color='green')
    plt.plot(y_train_pred, label='Valores Estimados (Treinamento)', color='blue')
    plt.plot(y_val, label='Valores Verdadeiros (Validação)', color='red')
    plt.plot(y_val_pred, label='Valores Estimados (Validação)', color='orange')

    plt.xlabel('Amostra')
    plt.ylabel('Valor de y')
    plt.title('Valores Verdadeiros e Estimados de y no Treinamento e Validação')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()




def plot_rmse(history, model, X_val, y_val):

    y_pred = model.predict(X_val)
    rmse_test = np.sqrt(np.mean(np.square(y_pred - y_val)))

    train_rmse = history.history['root_mean_squared_error']
    val_rmse = history.history['val_root_mean_squared_error']
    epochs = range(1, len(train_rmse) + 1)

    plt.figure(figsize=(10, 6))

    plt.plot(epochs, train_rmse, label='RMSE Treinamento', color='blue')
    plt.plot(epochs, val_rmse, label='RMSE Validação', color='orange')
    plt.plot(epochs, rmse_test, label='RMSE Teste', color='green')

    plt.xlabel('Época')
    plt.ylabel('RMSE')
    plt.title('Valores de RMSE de Treinamento, Validação e Teste')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

class MyCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        print('.', end=' ')
        if (epoch % 10) == 0:
          print(f"Epoch {epoch+1}: loss = {logs['loss']} rmse= {logs['root_mean_squared_error']}")
        if (epoch + 1 )% epochs == 0:
          self.model.save_weights(f"{save_path}/{modelo}_{city}_model_weights_epoch{epoch+1}.h5")
callback = MyCallback()


early_stopping = EarlyStopping(monitor='val_loss', min_delta=min_delta, patience=patience, restore_best_weights=True)

model_checkpoint = ModelCheckpoint(f"{save_path}/{modelo}_{city}_model_weights_epoch.h5", save_best_only=True)



@tf.function
def heat_equation_loss(y_true, y_pred):
    k = 0.024  # Thermal conductivity of air (W/mK)
    rho = 1.225  # Density of air (kg/m³)
    Cp = 1005  # Specific heat capacity of air (J/kgK)
    alpha = k / (rho * Cp)  # Thermal diffusivity of air (m²/s)

    # Calculate second derivative for all time steps (vectorized)
    second_derivative = alpha * (y_pred[:-2] - 2 * y_pred[1:-1] + y_pred[2:])

    # Calculate temperature values based on second derivative
    temperature = y_pred[1:-1] + second_derivative

    # Calculate mean squared error using TensorFlow operation
    loss = tf.reduce_mean(tf.square(y_true[1:-1] - temperature))

    return loss

class HeatEquationLoss(tf.keras.losses.Loss):
    def __init__(self, name='heat_equation_loss', **kwargs):
        super(HeatEquationLoss, self).__init__(name=name, **kwargs)

    def call(self, y_true, y_pred):
        return heat_equation_loss(y_true, y_pred)

# Instanciar a classe de perda personalizada registrada
custom_loss = HeatEquationLoss()

# Define your model architecture
def build_model():
  inputs = Input(shape=(X.shape[1],))
  hidden1 = Dense(320, activation="relu")(inputs)
  hidden2 = Dense(80, activation="relu")(hidden1)
  hidden3 = Dense(80, activation="relu")(hidden2)
  hidden4 = Dense(80, activation="relu")(hidden3)
  hidden5 = Dense(16, activation="relu")(hidden4)
  hidden6 = Dense(12, activation="relu")(hidden5)
  hidden7 = Dense(7, activation="relu")(hidden6)
  output = Dense(1)(hidden7)
  model = Model(inputs=inputs, outputs=output)
  return model

kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)
pinn = []
dl = []
rmse = []
rmse_dl = []
mlp_time=[]
# Inicializar listas para armazenar resultados de treinamento e teste
train_scores = []
test_scores = []

history = None
for i, (train_index, test_index) in enumerate(kfold.split(X)):
  results = []
  if(i >= foldMin and i <= foldMax):
    model = build_model()
    #model.compile(loss=tf.keras.losses.MeanSquaredError(), metrics=[RootMeanSquaredError()], optimizer=Adam(learning_rate=learning_rate))
    model.compile(loss=custom_loss, metrics=[RootMeanSquaredError()], optimizer=Adam(learning_rate=learning_rate))
    X_fold_train = X[train_index]
    y_fold_train = y[train_index]
    X_fold_test = X[test_index]
    y_fold_test = y[test_index]

    inicio = time.time()
    print(f"MLP({i}) City({city}) Time:({inicio})")

    history = model.fit(X_fold_train, y_fold_train, epochs=epochs, batch_size=16, validation_split=test_size, verbose=0,callbacks=[callback,early_stopping,model_checkpoint])
    fim = time.time()

    # Carregar o melhor modelo salvo pelo Model Checkpoint
    best_model = tf.keras.models.load_model(
    f"{save_path}/{modelo}_{city}_model_weights_epoch.h5",
    custom_objects={'HeatEquationLoss': HeatEquationLoss}
    )

    # Avaliar o modelo nos conjuntos de treinamento e teste
    train_score = best_model.evaluate(X_fold_train, y_fold_train)
    test_score = best_model.evaluate(X_fold_test, y_fold_test)

    train_scores.append(train_score)
    test_scores.append(test_score)

    num_epochs = len(history.epoch)

    mlp_time = fim - inicio
    y_pred = model.predict(X_fold_test)

    results.append([city,str(i),sqrt(mean_squared_error(y_fold_test, y_pred)),mlp_time, num_epochs,train_score[0],train_score[1],test_score[0],test_score[1]])
    values = ','.join(str(v) for v in results)
    with open(file_path + modelo+'_'+city+'.csv', 'a', newline='') as file:
      writer = csv.writer(file)
      writer.writerows(results)
      print("List saved to CSV file successfully.")
    plot_training_history(history)

plot_training_history_f(history, model, X_fold_train, y_fold_train, X_fold_test, y_fold_test)

# Converter as listas em arrays para facilitar a manipulação
train_scores = np.array(train_scores)
test_scores = np.array(test_scores)

    # Imprimir os scores de treinamento e teste para cada fold
for fold in range(num_folds):
    print(f"Fold {fold + 1} - Train Loss: {train_scores[fold, 0]}, Train Accuracy: {train_scores[fold, 1]}")
    print(f"Fold {fold + 1} - Test Loss: {test_scores[fold, 0]}, Test Accuracy: {test_scores[fold, 1]}")